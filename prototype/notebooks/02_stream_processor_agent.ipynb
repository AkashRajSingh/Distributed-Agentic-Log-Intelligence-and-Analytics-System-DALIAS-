import time
import json
import random
import numpy as np
import matplotlib.pyplot as plt

# Simple anomaly rule engine
def is_anomaly(log):
    parsed = json.loads(log)
    return parsed["level"] == "ERROR" or "Failure" in parsed["message"]

# Batch processor
def process_batch(batch):
    anomalies = []
    for log in batch:
        if is_anomaly(log):
            anomalies.append(log)
    return anomalies

# Scalability experiment
batch_sizes = [100, 500, 1000, 5000, 10000]
processing_times = []

for b in batch_sizes:
    batch = [json.dumps({
        "timestamp": time.time(),
        "service": random.choice(["auth", "payment", "search"]),
        "level": random.choice(["INFO", "WARN", "ERROR"]),
        "message": random.choice(["OK", "Timeout", "DB Failure"]),
    }) for _ in range(b)]

    start = time.time()
    anomalies = process_batch(batch)
    end = time.time()

    processing_times.append(end - start)

plt.figure(figsize=(10,5))
plt.plot(batch_sizes, processing_times)
plt.xlabel("Batch Size")
plt.ylabel("Processing Time (sec)")
plt.title("Stream Processor Scalability Test")
plt.grid(True)
plt.show()
